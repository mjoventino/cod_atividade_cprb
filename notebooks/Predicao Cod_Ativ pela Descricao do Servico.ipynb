{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from joblib import dump, load\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "# sklearn.__version__ == 0.23.2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#conda install -c anaconda nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(doc=None, string_=True):\n",
    "    ''' # turn a doc into clean tokens '''\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # prepare regex for char filtering\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    # remove punctuation from each word\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word.lower() for word in tokens if not word.isdigit()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    stop_words.update(['<br />'])\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    if string_: return \" \".join(tokens)\n",
    "    else: return tokens\n",
    "    \n",
    "def load_doc(filename):\n",
    "    ''' # load doc into memory '''\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "def predict_ml_classe(lc, text, l_vocab, pipe):\n",
    "    l_text_clean = clean_doc(text, False)\n",
    "    l_text_clean = [w for w in l_text_clean if w in l_vocab]\n",
    "    l_lc = list()\n",
    "    lc_clean = re.sub(r'[^\\w\\s]', '', str(lc))\n",
    "    if lc_clean in l_vocab:\n",
    "        l_lc.append(lc_clean)  \n",
    "        l_lc.extend(l_text_clean)    \n",
    "        l_lc = [w for w in l_lc if w != '']\n",
    "        return pipe.predict(l_lc)[0]\n",
    "    return pipe.predict(l_text_clean)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"../best_models/ML_model.pickle\", 'rb') as handle:\n",
    "    loaded_pipe = pickle.load(handle)\n",
    "# vocabulario\n",
    "loaded_vocab = load_doc(r'../best_models/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desenvolvimento de sistemas: classe 25\n"
     ]
    }
   ],
   "source": [
    "# Descrição de serviço de TI - classe 25\n",
    "cd = ''\n",
    "texto = 'desenvolvimento de sistemas'\n",
    "classe = predict_ml_classe(cd,texto, loaded_vocab, loaded_pipe)\n",
    "print(f'{texto}: classe {classe}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hospedagem: classe 40\n"
     ]
    }
   ],
   "source": [
    "# Descrição de serviço de hotelaria - classe 40\n",
    "cd = ''\n",
    "texto = 'hospedagem'\n",
    "classe = predict_ml_classe(cd,texto, loaded_vocab, loaded_pipe)\n",
    "print(f'{texto}: classe {classe}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obra de construção civil: classe 90\n"
     ]
    }
   ],
   "source": [
    "# Descrição de serviço de obra de construo civil grupo CNAE 412, 432, 433,439 - classe 90\n",
    "cd = ''\n",
    "texto = 'obra de construção civil'\n",
    "classe = predict_ml_classe(cd,texto, loaded_vocab, loaded_pipe)\n",
    "print(f'{texto}: classe {classe}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
